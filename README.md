# python-web-scraping

Note : This repository is under construction üõ†Ô∏è‚ö†Ô∏è

Hands-on workshop material on Web scraping using Python.

### To build and run site locally :

1. git clone https://github.com/MonashDataFluency/python-web-scraping.git
2. cd python-web-scraping
3. virtualenv -p python3 venv
4. source venv/bin/activate
5. pip install -r requirements.txt
6. mkdocs serve

Note : wptools might throw an error during installtion, in which case install other depencies as : 
- sudo apt install libcurl4-openssl-dev libssl-dev  

and then proceed to install wptools (via step 5 above)


### TODO: 
## General:
- [x] Rename the files
- [ ] Add References
- [x] Compile and build the website
- [x] githook for auto compile and build
- [ ] As many images (with brief explantions within) as possible : (LucidChart,  Google draw)
- [x] Add a Reference section
- [ ] Archive the website 
- [ ] Backup code/cell for requests

## Section 0
- [x] Complete the DF and regex section (pythex website)
- [x] Move the variable argument section to advanced topics
- [ ] Add more text/explanations


## Section 1
- [x] Add more about html in text and add an image
- [ ] Give more description in the image
- [ ] Fix the issue of broken image
- [ ] Add json section
- [ ] DOM inspector
- [ ] Talk a bit about RESTful WS
- [ ] Long term: Add images/flowchart for better explanation 
 
## Section 2 
- [ ] Shorten/Format the big html chunk
- [ ] Prettify the output of html
- [ ] Put more details on get/put requests (possibly visually)

## Section 3
- [x] Add more explanations

## Section 4
- [ ] itertools (show vanilla python way to do it)
- [ ] explain regex in detail (breakdown)
- [ ] matplotlib funcs

## Section 5
- [ ] Add MCQs - Scenario based legal/grey questions
 
